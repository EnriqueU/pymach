{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            mean = sum(scores) / float(len(scores))\n",
    "            std = sum((x-mean)**2 for x in scores)\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': mean,\n",
    "                 'std_score': std,\n",
    "            }\n",
    "            return pd.Series(dict(params.items() + d.items()))\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer,\\\n",
    "StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "models1 = { \n",
    "    'ExtraTreesClassifier': pipeline,\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = { \n",
    "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ExtraTreesClassifier__max_features',\n",
       " 'scaler',\n",
       " 'ExtraTreesClassifier__min_samples_leaf',\n",
       " 'ExtraTreesClassifier__max_depth',\n",
       " 'ExtraTreesClassifier',\n",
       " 'scaler__with_mean',\n",
       " 'ExtraTreesClassifier__bootstrap',\n",
       " 'ExtraTreesClassifier__class_weight',\n",
       " 'ExtraTreesClassifier__min_weight_fraction_leaf',\n",
       " 'ExtraTreesClassifier__verbose',\n",
       " 'ExtraTreesClassifier__criterion',\n",
       " 'ExtraTreesClassifier__min_samples_split',\n",
       " 'scaler__with_std',\n",
       " 'ExtraTreesClassifier__min_impurity_split',\n",
       " 'ExtraTreesClassifier__random_state',\n",
       " 'scaler__copy',\n",
       " 'ExtraTreesClassifier__oob_score',\n",
       " 'ExtraTreesClassifier__n_estimators',\n",
       " 'steps',\n",
       " 'ExtraTreesClassifier__warm_start',\n",
       " 'ExtraTreesClassifier__n_jobs',\n",
       " 'ExtraTreesClassifier__max_leaf_nodes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVC.\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.2s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f67569648b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f67569648b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#%%time\\nhelper1 = EstimatorSelectionHelper(model...ng='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-12-20T23:14:52.790501', 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'session': '9C4FB20070734C9C86343199F4060DB0', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['9C4FB20070734C9C86343199F4060DB0']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#%%time\\nhelper1 = EstimatorSelectionHelper(model...ng='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-12-20T23:14:52.790501', 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'session': '9C4FB20070734C9C86343199F4060DB0', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['9C4FB20070734C9C86343199F4060DB0'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#%%time\\nhelper1 = EstimatorSelectionHelper(model...ng='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-12-20T23:14:52.790501', 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'session': '9C4FB20070734C9C86343199F4060DB0', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-21-8ba2ef6d15ee>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f67178dc4b0, file \"<ipython-input-21-8ba2ef6d15ee>\", line 3>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f67178dc4b0, file \"<ipython-input-21-8ba2ef6d15ee>\", line 3>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f67178dc4b0, file \"<ipython-input-21-8ba2ef6d15ee>\", line 3>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EstimatorSelectionHelper': <class __main__.EstimatorSelectionHelper>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...=-1)\\nhelper1.score_summary(sort_by='min_score')\", u\"helper1 = EstimatorSelectionHelper(models1, pa...coring='f1', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accurate', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Normalizer': <class 'sklearn.preprocessing.data.Normalizer'>, 'Out': {13:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  , 16:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  }, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EstimatorSelectionHelper': <class __main__.EstimatorSelectionHelper>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...=-1)\\nhelper1.score_summary(sort_by='min_score')\", u\"helper1 = EstimatorSelectionHelper(models1, pa...coring='f1', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accurate', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Normalizer': <class 'sklearn.preprocessing.data.Normalizer'>, 'Out': {13:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  , 16:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  }, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/guess/Desktop/core/Proyectos/ProyectoIGI/PyMach/Pruebas/Raspberri/Tx_0x01/<ipython-input-21-8ba2ef6d15ee> in <module>()\n      1 \n      2 \n----> 3 \n      4 #%%time\n      5 helper1 = EstimatorSelectionHelper(models1, params1)\n      6 helper1.fit(X_iris, y_iris, scoring='accuracy', n_jobs=-1)\n      7 helper1.score_summary()\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/guess/Desktop/core/Proyectos/ProyectoIGI/PyMach/Pruebas/Raspberri/Tx_0x01/<ipython-input-11-3140d1c32f6c> in fit(self=<__main__.EstimatorSelectionHelper instance>, X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), cv=3, n_jobs=-1, verbose=1, scoring='accuracy', refit=False)\n     16             print(\"Running GridSearchCV for %s.\" % key)\n     17             model = self.models[key]\n     18             params = self.params[key]\n     19             gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n     20                               verbose=verbose, scoring=scoring, refit=refit)\n---> 21             gs.fit(X,y)\n     22             self.grid_searches[key] = gs    \n     23 \n     24     def score_summary(self, sort_by='mean_score'):\n     25         def row(key, scores, params):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...      refit=False, scoring='accuracy', verbose=1), X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))\n    808         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    809             Target relative to X for classification or regression;\n    810             None for unsupervised learning.\n    811 \n    812         \"\"\"\n--> 813         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...     refit=False, scoring='accuracy', verbose=1)>\n        X = array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n        self.param_grid = {'n_estimators': [16, 32]}\n    814 \n    815 \n    816 class RandomizedSearchCV(BaseSearchCV):\n    817     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...      refit=False, scoring='accuracy', verbose=1), X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    556         )(\n    557             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    558                                     train, test, self.verbose, parameters,\n    559                                     self.fit_params, return_parameters=True,\n    560                                     error_score=self.error_score)\n--> 561                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    562                 for train, test in cv)\n    563 \n    564         # Out is a list of triplet: score, estimator, n_test_samples\n    565         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Dec 20 23:14:54 2016\nPID: 11335                                    Python 2.7.6: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), make_scorer(accuracy_score), array([ 17,  18,  19,  20,  21,  22,  23,  24,  ...,\n       142, 143, 144, 145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...07, 108, 109, 110, 111, 112, 113, 114, 115, 116]), 1, {'n_estimators': 16}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), make_scorer(accuracy_score), array([ 17,  18,  19,  20,  21,  22,  23,  24,  ...,\n       142, 143, 144, 145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...07, 108, 109, 110, 111, 112, 113, 114, 115, 116]), 1, {'n_estimators': 16}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer=make_scorer(accuracy_score), train=array([ 17,  18,  19,  20,  21,  22,  23,  24,  ...,\n       142, 143, 144, 145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...07, 108, 109, 110, 111, 112, 113, 114, 115, 116]), verbose=1, parameters={'n_estimators': 16}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1597     fit_params = fit_params if fit_params is not None else {}\n   1598     fit_params = dict([(k, _index_param_value(X, v, train))\n   1599                       for k, v in fit_params.items()])\n   1600 \n   1601     if parameters is not None:\n-> 1602         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...None,\n           verbose=0, warm_start=False))])>\n        parameters = {'n_estimators': 16}\n   1603 \n   1604     start_time = time.time()\n   1605 \n   1606     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), **kwargs={'n_estimators': 16})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method Pipeline._set_params of Pipeline(s...None,\n           verbose=0, warm_start=False))])>\n        kwargs = {'n_estimators': 16}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), steps_attr='steps', **params={'n_estimators': 16})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...None,\n           verbose=0, warm_start=False))])>\n        params = {'n_estimators': 16}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), **params={'n_estimators': 16})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'n_estimators'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter n_estimators for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8ba2ef6d15ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#%%time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhelper1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEstimatorSelectionHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhelper1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_iris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_iris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mhelper1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-3140d1c32f6c>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[0;32m     19\u001b[0m             gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n\u001b[0;32m     20\u001b[0m                               verbose=verbose, scoring=scoring, refit=refit)\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m--> 813\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    559\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 561\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m                 for train, test in cv)\n\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f67569648b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f67569648b0, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#%%time\\nhelper1 = EstimatorSelectionHelper(model...ng='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-12-20T23:14:52.790501', 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'session': '9C4FB20070734C9C86343199F4060DB0', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['9C4FB20070734C9C86343199F4060DB0']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#%%time\\nhelper1 = EstimatorSelectionHelper(model...ng='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-12-20T23:14:52.790501', 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'session': '9C4FB20070734C9C86343199F4060DB0', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['9C4FB20070734C9C86343199F4060DB0'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#%%time\\nhelper1 = EstimatorSelectionHelper(model...ng='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-12-20T23:14:52.790501', 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'session': '9C4FB20070734C9C86343199F4060DB0', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1F441C15321241CB8DAFED033D0DD4C9', 'msg_type': 'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-21-8ba2ef6d15ee>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f67178dc4b0, file \"<ipython-input-21-8ba2ef6d15ee>\", line 3>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f67178dc4b0, file \"<ipython-input-21-8ba2ef6d15ee>\", line 3>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f67178dc4b0, file \"<ipython-input-21-8ba2ef6d15ee>\", line 3>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EstimatorSelectionHelper': <class __main__.EstimatorSelectionHelper>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...=-1)\\nhelper1.score_summary(sort_by='min_score')\", u\"helper1 = EstimatorSelectionHelper(models1, pa...coring='f1', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accurate', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Normalizer': <class 'sklearn.preprocessing.data.Normalizer'>, 'Out': {13:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  , 16:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  }, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'EstimatorSelectionHelper': <class __main__.EstimatorSelectionHelper>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...=-1)\\nhelper1.score_summary(sort_by='min_score')\", u\"helper1 = EstimatorSelectionHelper(models1, pa...coring='f1', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accurate', n_jobs=-1)\\nhelper1.score_summary()\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'import pandas as pd\\nfrom sklearn.grid_search ... c not in columns]\\n\\n        return df[columns]', u\"from sklearn import datasets\\n\\niris = dataset...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"helper1 = EstimatorSelectionHelper(models1, pa...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u'get_ipython().run_cell_magic(u\\'time\\', u\\'\\',...curacy\\', n_jobs=-1)\\\\nhelper1.score_summary()\")', u\"#%%time\\nhelper1 = EstimatorSelectionHelper(mo...='accuracy', n_jobs=-1)\\nhelper1.score_summary()\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", u\"from sklearn import datasets\\nfrom sklearn.pre...': [1, 10], 'gamma': [0.001, 0.0001]},\\n    ]\\n}\", ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Normalizer': <class 'sklearn.preprocessing.data.Normalizer'>, 'Out': {13:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  , 16:                      estimator min_score mean_sc...  10  0.0001     rbf           NaN          NaN  }, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/guess/Desktop/core/Proyectos/ProyectoIGI/PyMach/Pruebas/Raspberri/Tx_0x01/<ipython-input-21-8ba2ef6d15ee> in <module>()\n      1 \n      2 \n----> 3 \n      4 #%%time\n      5 helper1 = EstimatorSelectionHelper(models1, params1)\n      6 helper1.fit(X_iris, y_iris, scoring='accuracy', n_jobs=-1)\n      7 helper1.score_summary()\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/guess/Desktop/core/Proyectos/ProyectoIGI/PyMach/Pruebas/Raspberri/Tx_0x01/<ipython-input-11-3140d1c32f6c> in fit(self=<__main__.EstimatorSelectionHelper instance>, X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), cv=3, n_jobs=-1, verbose=1, scoring='accuracy', refit=False)\n     16             print(\"Running GridSearchCV for %s.\" % key)\n     17             model = self.models[key]\n     18             params = self.params[key]\n     19             gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n     20                               verbose=verbose, scoring=scoring, refit=refit)\n---> 21             gs.fit(X,y)\n     22             self.grid_searches[key] = gs    \n     23 \n     24     def score_summary(self, sort_by='mean_score'):\n     25         def row(key, scores, params):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...      refit=False, scoring='accuracy', verbose=1), X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))\n    808         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    809             Target relative to X for classification or regression;\n    810             None for unsupervised learning.\n    811 \n    812         \"\"\"\n--> 813         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...     refit=False, scoring='accuracy', verbose=1)>\n        X = array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n        self.param_grid = {'n_estimators': [16, 32]}\n    814 \n    815 \n    816 class RandomizedSearchCV(BaseSearchCV):\n    817     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...      refit=False, scoring='accuracy', verbose=1), X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    556         )(\n    557             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    558                                     train, test, self.verbose, parameters,\n    559                                     self.fit_params, return_parameters=True,\n    560                                     error_score=self.error_score)\n--> 561                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    562                 for train, test in cv)\n    563 \n    564         # Out is a list of triplet: score, estimator, n_test_samples\n    565         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Dec 20 23:14:54 2016\nPID: 11335                                    Python 2.7.6: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), make_scorer(accuracy_score), array([ 17,  18,  19,  20,  21,  22,  23,  24,  ...,\n       142, 143, 144, 145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...07, 108, 109, 110, 111, 112, 113, 114, 115, 116]), 1, {'n_estimators': 16}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), make_scorer(accuracy_score), array([ 17,  18,  19,  20,  21,  22,  23,  24,  ...,\n       142, 143, 144, 145, 146, 147, 148, 149]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...07, 108, 109, 110, 111, 112, 113, 114, 115, 116]), 1, {'n_estimators': 16}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), X=array([[ 5.1,  3.5,  1.4,  0.2],\n       [ 4.9,  ...4,  5.4,  2.3],\n       [ 5.9,  3. ,  5.1,  1.8]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), scorer=make_scorer(accuracy_score), train=array([ 17,  18,  19,  20,  21,  22,  23,  24,  ...,\n       142, 143, 144, 145, 146, 147, 148, 149]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...07, 108, 109, 110, 111, 112, 113, 114, 115, 116]), verbose=1, parameters={'n_estimators': 16}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1597     fit_params = fit_params if fit_params is not None else {}\n   1598     fit_params = dict([(k, _index_param_value(X, v, train))\n   1599                       for k, v in fit_params.items()])\n   1600 \n   1601     if parameters is not None:\n-> 1602         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...None,\n           verbose=0, warm_start=False))])>\n        parameters = {'n_estimators': 16}\n   1603 \n   1604     start_time = time.time()\n   1605 \n   1606     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), **kwargs={'n_estimators': 16})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method Pipeline._set_params of Pipeline(s...None,\n           verbose=0, warm_start=False))])>\n        kwargs = {'n_estimators': 16}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), steps_attr='steps', **params={'n_estimators': 16})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...None,\n           verbose=0, warm_start=False))])>\n        params = {'n_estimators': 16}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('scaler', StandardScaler(copy=T...=None,\n           verbose=0, warm_start=False))]), **params={'n_estimators': 16})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'n_estimators'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter n_estimators for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_iris, y_iris, scoring='accuracy', n_jobs=-1)\n",
    "helper1.score_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    '__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "            'clf__alpha': (0.00001, 0.000001),\n",
    "            'clf__penalty': ('l2', 'elasticnet'),\n",
    "            #'clf__n_iter': (10, 50, 80),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/discriminant_analysis.py:457: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model      Mean       STD\n",
      "7          AdaBoostClassifier  0.798338  0.048969\n",
      "9  GradientBoostingClassifier  0.742983  0.060308\n",
      "3        KNeighborsClassifier  0.742780  0.072794\n",
      "6        ExtraTreesClassifier  0.736634  0.116844\n",
      "8      RandomForestClassifier  0.709850  0.117016\n",
      "1                         SVC  0.683069  0.056990\n",
      "4      DecisionTreeClassifier  0.675291  0.067551\n",
      "2                  GaussianNB  0.594325  0.035160\n",
      "5          LogisticRegression  0.545059  0.049457\n",
      "0                         LDA  0.527599  0.053464\n",
      "CPU times: user 18min 21s, sys: 6.67 s, total: 18min 28s\n",
      "Wall time: 18min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import define\n",
    "import analyze\n",
    "import prepare\n",
    "import feature_selection\n",
    "import evaluate\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "import pandas as pd\n",
    "\n",
    "#name = \"datasets/iris.csv\"\n",
    "name = \"datasets/LocalizationNew.csv\"\n",
    "#name = \"datasets/LocalizationOld.csv\"\n",
    "#name = \"datasets/seguridad.csv\"\n",
    "#name = \"datasets/breast-cancer-wisconsin.csv\"\n",
    "#name = \"breast-cancer-wisconsin.csv\"\n",
    "#name = \"inputBus.csv\"\n",
    "# className = \"Ruta\"\n",
    "#className = \"CATEGORY\"\n",
    "#className = \"class\"\n",
    "className = \"position\"\n",
    "\n",
    "#STEP 0: Define workflow parameters\n",
    "definer = define.Define(nameData=name, className=className).pipeline()\n",
    "\n",
    "#STEP 1: Analyze data by ploting it\n",
    "#analyze.Analyze(definer).pipeline()\n",
    "\n",
    "#STEP 2: Prepare data by scaling, normalizing, etc. \n",
    "preparer = prepare.Prepare(definer).pipeline()\n",
    "\n",
    "#STEP 3: Feature selection\n",
    "featurer = feature_selection.FeatureSelection(definer).pipeline()\n",
    "\n",
    "#STEP4: Evalute the algorithms by using the pipelines\n",
    "evaluator = evaluate.Evaluate(definer, preparer, featurer).pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preparer', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "       transformer_weights=None)), ('featurer', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, ran...timators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip = evaluator.pipelines[6][1]\n",
    "pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExtraTreesClassifier': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       " 'ExtraTreesClassifier__bootstrap': False,\n",
       " 'ExtraTreesClassifier__class_weight': None,\n",
       " 'ExtraTreesClassifier__criterion': 'gini',\n",
       " 'ExtraTreesClassifier__max_depth': None,\n",
       " 'ExtraTreesClassifier__max_features': 'auto',\n",
       " 'ExtraTreesClassifier__max_leaf_nodes': None,\n",
       " 'ExtraTreesClassifier__min_impurity_split': 1e-07,\n",
       " 'ExtraTreesClassifier__min_samples_leaf': 1,\n",
       " 'ExtraTreesClassifier__min_samples_split': 2,\n",
       " 'ExtraTreesClassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'ExtraTreesClassifier__n_estimators': 10,\n",
       " 'ExtraTreesClassifier__n_jobs': 1,\n",
       " 'ExtraTreesClassifier__oob_score': False,\n",
       " 'ExtraTreesClassifier__random_state': None,\n",
       " 'ExtraTreesClassifier__verbose': 0,\n",
       " 'ExtraTreesClassifier__warm_start': False,\n",
       " 'featurer': FeatureUnion(n_jobs=1,\n",
       "        transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False)), ('extraTC', ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,...timators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))],\n",
       "        transformer_weights=None),\n",
       " 'featurer__extraTC': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       " 'featurer__extraTC__bootstrap': False,\n",
       " 'featurer__extraTC__class_weight': None,\n",
       " 'featurer__extraTC__criterion': 'gini',\n",
       " 'featurer__extraTC__max_depth': None,\n",
       " 'featurer__extraTC__max_features': 'auto',\n",
       " 'featurer__extraTC__max_leaf_nodes': None,\n",
       " 'featurer__extraTC__min_impurity_split': 1e-07,\n",
       " 'featurer__extraTC__min_samples_leaf': 1,\n",
       " 'featurer__extraTC__min_samples_split': 2,\n",
       " 'featurer__extraTC__min_weight_fraction_leaf': 0.0,\n",
       " 'featurer__extraTC__n_estimators': 10,\n",
       " 'featurer__extraTC__n_jobs': 1,\n",
       " 'featurer__extraTC__oob_score': False,\n",
       " 'featurer__extraTC__random_state': None,\n",
       " 'featurer__extraTC__verbose': 0,\n",
       " 'featurer__extraTC__warm_start': False,\n",
       " 'featurer__n_jobs': 1,\n",
       " 'featurer__pca': PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'featurer__pca__copy': True,\n",
       " 'featurer__pca__iterated_power': 'auto',\n",
       " 'featurer__pca__n_components': 2,\n",
       " 'featurer__pca__random_state': None,\n",
       " 'featurer__pca__svd_solver': 'auto',\n",
       " 'featurer__pca__tol': 0.0,\n",
       " 'featurer__pca__whiten': False,\n",
       " 'featurer__transformer_list': [('pca',\n",
       "   PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False)),\n",
       "  ('extraTC',\n",
       "   ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False))],\n",
       " 'featurer__transformer_weights': None,\n",
       " 'preparer': FeatureUnion(n_jobs=1,\n",
       "        transformer_list=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "        transformer_weights=None),\n",
       " 'preparer__n_jobs': 1,\n",
       " 'preparer__scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'preparer__scaler__copy': True,\n",
       " 'preparer__scaler__with_mean': True,\n",
       " 'preparer__scaler__with_std': True,\n",
       " 'preparer__transformer_list': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'preparer__transformer_weights': None,\n",
       " 'steps': [('preparer', FeatureUnion(n_jobs=1,\n",
       "          transformer_list=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          transformer_weights=None)), ('featurer', FeatureUnion(n_jobs=1,\n",
       "          transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False)), ('extraTC', ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,...timators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False))],\n",
       "          transformer_weights=None)), ('ExtraTreesClassifier',\n",
       "   ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612920404736\n",
      "CPU times: user 1min 43s, sys: 5.82 s, total: 1min 49s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_GBC = { \n",
    "    'featurer__extraTC__n_estimators':  [10, 16, 32],\n",
    "    'featurer__extraTC__criterion': ['gini','entropy'],\n",
    "    'featurer__extraTC__n_jobs': [-1],\n",
    "    'featurer__pca__svd_solver': ['auto', 'full', 'arpack', 'randomized'],\n",
    "    'featurer__pca__whiten': [True],\n",
    "    'GradientBoostingClassifier__n_estimators': [100, 150, 200],\n",
    "    'GradientBoostingClassifier__learning_rate': [0.1, 0.2, 0.4, 0.8, 1.0]    \n",
    "}\n",
    "param_AdaBoost = { \n",
    "    'featurer__extraTC__n_estimators':  [10, 16, 32],\n",
    "    'featurer__extraTC__criterion': ['gini','entropy'],\n",
    "    'featurer__extraTC__n_jobs': [-1],\n",
    "    'featurer__pca__svd_solver': ['auto', 'full', 'arpack', 'randomized'],\n",
    "    'featurer__pca__whiten': [True],\n",
    "    'AdaBoostClassifier__base_estimator__criterion': ['gini','entropy'],\n",
    "    'AdaBoostClassifier__learning_rate': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'AdaBoostClassifier__n_estimators': [50, 100, 150, 200]\n",
    "}\n",
    "param_ExtraTrees = { \n",
    "    'ExtraTreesClassifier__bootstrap': [True],\n",
    "    'ExtraTreesClassifier__class_weight': [None],\n",
    "    'ExtraTreesClassifier__criterion': ['gini'],\n",
    "    'ExtraTreesClassifier__max_depth': [None],\n",
    "    'ExtraTreesClassifier__max_features': [None],\n",
    "    'ExtraTreesClassifier__max_leaf_nodes': [None],\n",
    "    'ExtraTreesClassifier__min_impurity_split': [1e-07],\n",
    "    'ExtraTreesClassifier__min_samples_leaf': [1],\n",
    "    'ExtraTreesClassifier__min_samples_split': [2],\n",
    "    'ExtraTreesClassifier__min_weight_fraction_leaf': [0.0],\n",
    "    'ExtraTreesClassifier__n_estimators': [905],\n",
    "    'ExtraTreesClassifier__n_jobs': [1],\n",
    "    'ExtraTreesClassifier__oob_score': [False],\n",
    "    'ExtraTreesClassifier__random_state': [2],\n",
    "    'ExtraTreesClassifier__verbose': [False],\n",
    "    'ExtraTreesClassifier__warm_start': [False]\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(estimator=pip, param_grid=param_ExtraTrees)\n",
    "gsearch.fit(definer.X, definer.y)\n",
    "print(gsearch.best_score_)\n",
    "improvedModel = gsearch.best_estimator_\n",
    "#print(improvedModel.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_ExtraTreesClassifier__bootstrap</th>\n",
       "      <th>param_ExtraTreesClassifier__class_weight</th>\n",
       "      <th>param_ExtraTreesClassifier__criterion</th>\n",
       "      <th>param_ExtraTreesClassifier__max_depth</th>\n",
       "      <th>param_ExtraTreesClassifier__max_features</th>\n",
       "      <th>param_ExtraTreesClassifier__max_leaf_nodes</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.242698</td>\n",
       "      <td>3.648133</td>\n",
       "      <td>0.61292</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598674</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.702311</td>\n",
       "      <td>0.997788</td>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.998157</td>\n",
       "      <td>13.367403</td>\n",
       "      <td>0.078531</td>\n",
       "      <td>0.06792</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      36.242698         3.648133          0.61292          0.997931   \n",
       "\n",
       "  param_ExtraTreesClassifier__bootstrap  \\\n",
       "0                                  True   \n",
       "\n",
       "  param_ExtraTreesClassifier__class_weight  \\\n",
       "0                                     None   \n",
       "\n",
       "  param_ExtraTreesClassifier__criterion param_ExtraTreesClassifier__max_depth  \\\n",
       "0                                  gini                                  None   \n",
       "\n",
       "  param_ExtraTreesClassifier__max_features  \\\n",
       "0                                     None   \n",
       "\n",
       "  param_ExtraTreesClassifier__max_leaf_nodes       ...        \\\n",
       "0                                       None       ...         \n",
       "\n",
       "  split0_test_score split0_train_score split1_test_score split1_train_score  \\\n",
       "0          0.598674           0.997849          0.702311           0.997788   \n",
       "\n",
       "  split2_test_score split2_train_score std_fit_time std_score_time  \\\n",
       "0          0.537752           0.998157    13.367403       0.078531   \n",
       "\n",
       "  std_test_score std_train_score  \n",
       "0        0.06792        0.000162  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExtraTreesClassifier__bootstrap': True,\n",
       " 'ExtraTreesClassifier__class_weight': None,\n",
       " 'ExtraTreesClassifier__criterion': 'gini',\n",
       " 'ExtraTreesClassifier__max_depth': None,\n",
       " 'ExtraTreesClassifier__max_features': None,\n",
       " 'ExtraTreesClassifier__max_leaf_nodes': None,\n",
       " 'ExtraTreesClassifier__min_impurity_split': 1e-07,\n",
       " 'ExtraTreesClassifier__min_samples_leaf': 1,\n",
       " 'ExtraTreesClassifier__min_samples_split': 2,\n",
       " 'ExtraTreesClassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'ExtraTreesClassifier__n_estimators': 905,\n",
       " 'ExtraTreesClassifier__n_jobs': 1,\n",
       " 'ExtraTreesClassifier__oob_score': False,\n",
       " 'ExtraTreesClassifier__random_state': 2,\n",
       " 'ExtraTreesClassifier__verbose': False,\n",
       " 'ExtraTreesClassifier__warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExtraTreesClassifier__bootstrap': True,\n",
       " 'ExtraTreesClassifier__class_weight': None,\n",
       " 'ExtraTreesClassifier__criterion': 'gini',\n",
       " 'ExtraTreesClassifier__max_depth': None,\n",
       " 'ExtraTreesClassifier__max_features': None,\n",
       " 'ExtraTreesClassifier__max_leaf_nodes': None,\n",
       " 'ExtraTreesClassifier__min_impurity_split': 1e-07,\n",
       " 'ExtraTreesClassifier__min_samples_leaf': 1,\n",
       " 'ExtraTreesClassifier__min_samples_split': 2,\n",
       " 'ExtraTreesClassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'ExtraTreesClassifier__n_estimators': 905,\n",
       " 'ExtraTreesClassifier__n_jobs': 1,\n",
       " 'ExtraTreesClassifier__oob_score': False,\n",
       " 'ExtraTreesClassifier__random_state': 2,\n",
       " 'ExtraTreesClassifier__verbose': False,\n",
       " 'ExtraTreesClassifier__warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['params'][gsearch.best_index_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Improve module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pkg_resources",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5ecca1ffea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/guess/Desktop/core/pymach/pymach/analyze.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcufflinks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_plot_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/plotly/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m from plotly import (plotly, graph_objs, grid_objs, tools, utils, session,\n\u001b[0m\u001b[1;32m     32\u001b[0m                     offline)\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/plotly/plotly/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m from . plotly import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msign_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mupdate_plot_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/plotly/plotly/plotly.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPBasicAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchunked_requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m from plotly.session import (sign_in, update_session_plot_options,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/plotly/tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from plotly.files import (CONFIG_FILE, CREDENTIALS_FILE, FILE_CONTENT,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/plotly/graph_reference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pkg_resources"
     ]
    }
   ],
   "source": [
    "import define\n",
    "import analyze\n",
    "import prepare\n",
    "import feature_selection\n",
    "import evaluate\n",
    "\n",
    "# from sklearn import datasets\n",
    "# from sklearn.preprocessing import MinMaxScaler, Normalizer,\\\n",
    "# StandardScaler\n",
    "# from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# iris = datasets.load_iris()\n",
    "# X_iris = iris.data\n",
    "# y_iris = iris.target\n",
    "data_name = \"iris.csv\"\n",
    "class_name = \"class\"\n",
    "definer = define.Define(\n",
    "        data_name=data_name,\n",
    "        header=None,\n",
    "        class_name=class_name).pipeline()\n",
    "\n",
    "preparer = prepare.Prepare(definer).pipeline()\n",
    "featurer = feature_selection.FeatureSelection(definer).pipeline()\n",
    "evaluator = evaluate.Evaluate(definer, preparer, featurer).buildPipelines()\n",
    "\n",
    "# def gradientboosting_param(self):\n",
    "#     parameters = { \n",
    "#         'featurer__extraTC__n_estimators':  [10, 16, 32],\n",
    "#         'featurer__extraTC__criterion': ['gini','entropy'],\n",
    "#         'featurer__extraTC__n_jobs': [-1],\n",
    "#         'featurer__pca__svd_solver': ['auto', 'full', 'arpack', 'randomized'],\n",
    "#         'featurer__pca__whiten': [True],\n",
    "#         'GradientBoostingClassifier__n_estimators': [100, 150, 200],\n",
    "#         'GradientBoostingClassifier__learning_rate': [0.1, 0.2, 0.4, 0.8, 1.0]    \n",
    "#     }\n",
    "\n",
    "#     return parameters\n",
    "\n",
    "# # def adaboost_param(self):\n",
    "# #     parameters = { \n",
    "# #         'featurer__extraTC__n_estimators':  [10, 16, 32],\n",
    "# #         'featurer__extraTC__criterion': ['gini','entropy'],\n",
    "# #         'featurer__extraTC__n_jobs': [-1],\n",
    "# #         'featurer__pca__svd_solver': ['auto', 'full', 'arpack', 'randomized'],\n",
    "# #         'featurer__pca__whiten': [True],\n",
    "# #         'AdaBoostClassifier__base_estimator__criterion': ['gini','entropy'],\n",
    "# #         'AdaBoostClassifier__learning_rate': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "# #         'AdaBoostClassifier__n_estimators': [50, 100, 150, 200]\n",
    "# #     }\n",
    "\n",
    "# #     return parameters\n",
    "\n",
    "# def improve(self):\n",
    "#     pipeline = evaluator\n",
    "\n",
    "#     parameters = self.gradientboosting_param()\n",
    "\n",
    "#     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "#     print(\"Performing grid search...\")\n",
    "#     print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "#     print(\"parameters:\")\n",
    "#     print(parameters)\n",
    "#     t0 = time()\n",
    "#     grid_search.fit(self.definer.X, self.definer.y)\n",
    "#     print(\"done in %0.3fs\" % (time() - t0))\n",
    "#     print()\n",
    "\n",
    "#     print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "improve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
